{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56793669-b409-439e-a6cd-09b92598051d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.cifar10 import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3992f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9036a985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0348480e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ReLU, Dropout, Flatten, Dense\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab18862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934adf34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_tmp_folder_path = 'C:\\hyundai_cgan_data' + '\\\\circular_vane_design' + '\\\\tmp_input_data_circular'\n",
    "source_dsp_folder_path = 'C:\\hyundai_cgan_data' + '\\\\circular_vane_design' + '\\\\dsp_input_data_circular'\n",
    "target_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\dataset\\CIRCULAR_VANE_Images_240220\\CIRCULAR_VANE_Images_240220\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d02d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "target_elements = os.listdir(target_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed414c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "disc_temp_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\CCGAN\\mat_ccgan\\disc_temp_mat\"\n",
    "disc_disp_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\CCGAN\\mat_ccgan\\disc_disp_mat\"\n",
    "gen_temp_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\CCGAN\\mat_ccgan\\gen_temp_mat\"\n",
    "gen_disp_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\CCGAN\\mat_ccgan\\gen_disp_mat\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f081e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c658dee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEVELOPING X_train MATRIX\n",
    "from IPython import display\n",
    "\n",
    "def get_images(tmp_elements,disp_elements,y_elements,size,id):\n",
    "  X= np.zeros((size,id,id,2))\n",
    "  \n",
    "  for index, (tmp_element, dsp_element) in enumerate(zip(tmp_elements, disp_elements)):\n",
    "      # Load images for each channel\n",
    "      tmp_element_path = os.path.join(disc_temp_path,str(id))\n",
    "      tmp_element_path = os.path.join(tmp_element_path,tmp_elements[index])\n",
    "      dsp_element_path = os.path.join(disc_disp_path,str(id))\n",
    "      dsp_element_path = os.path.join(dsp_element_path,disp_elements[index])\n",
    "      #arr.append([tmp_element_path,dsp_element_path]) \n",
    "    \n",
    "      img_tmp = imread(tmp_element_path)\n",
    "      img_dsp = imread(dsp_element_path)\n",
    "\n",
    "      # Reshape images for each channel\n",
    "      \n",
    "      img_tmp = img_tmp.reshape((id,id, 1))\n",
    "      img_dsp = img_dsp.reshape((id,id, 1))\n",
    "      '''\n",
    "      plt.subplot(2,1,1)\n",
    "      plt.imshow(img_tmp)\n",
    "      plt.axis(\"off\")\n",
    "      plt.subplot(2,1,2)\n",
    "      plt.imshow(img_dsp)\n",
    "      plt.axis(\"off\")\n",
    "      display.clear_output(wait=True)\n",
    "      '''\n",
    "      #print('///')\n",
    "      #print(img_tmp)\n",
    "      img_tmp=img_tmp/0.5-1\n",
    "    \n",
    "      img_dsp=img_dsp/0.5-1\n",
    "      # Combine channels\n",
    "      #print(img_tmp.shape)\n",
    "      img_combined = (np.concatenate((img_tmp, img_dsp), axis=2))\n",
    "    \n",
    "      #print(img_combined.min,img_combined.max)   \n",
    "      #print(img_combined)\n",
    "      # Assign to X_train\n",
    "      X[index] = img_combined\n",
    "      #print(arr)\n",
    "  return X\n",
    "\n",
    "\n",
    "def get_Y(y_elements,size=20):\n",
    "  Y= np.zeros((size,256,256,1))\n",
    "  # DEVELOPING Y_train MATRIX\n",
    "  for index,Y_train_element in enumerate(y_elements):\n",
    "      element_path = os.path.join(target_folder_path,target_elements[index])\n",
    "      #print(element_path)\n",
    "      img = imread(element_path)\n",
    "      img = np.mean(img, axis=2)\n",
    "      img = img/127.5-1        \n",
    "      img = img.reshape((256, 256, 1))\n",
    "      Y[index] = img\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dda77f0-a6bf-435b-8995-fb83907547db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mtmp_array\u001b[49m[\u001b[38;5;241m0\u001b[39m], disp_array[\u001b[38;5;241m0\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tmp_array' is not defined"
     ]
    }
   ],
   "source": [
    "list(enumerate(zip(tmp_array[0], disp_array[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2e9c6-b8e0-43f0-8289-8c7ef5debd87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\dataset\\CIRCULAR_VANE_Images_240220\\CIRCULAR_VANE_Images_240220\\CIR_VANE_Shape_75.jpeg\")\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ad775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "temp_256 = sorted(os.listdir(os.path.join(disc_temp_path, '256')))\n",
    "disp_256 = sorted(os.listdir(os.path.join(disc_disp_path, '256')))\n",
    "\n",
    "\n",
    "\n",
    "disc_temp_128 = sorted(os.listdir(os.path.join(disc_temp_path, '128')))\n",
    "disc_temp_64 = sorted(os.listdir(os.path.join(disc_temp_path, '64')))\n",
    "disc_temp_32 = sorted(os.listdir(os.path.join(disc_temp_path, '32')))\n",
    "disc_temp_16 = sorted(os.listdir(os.path.join(disc_temp_path, '16')))\n",
    "\n",
    "gen_temp_64 = sorted(os.listdir(os.path.join(gen_temp_path, '64')))\n",
    "gen_temp_16 = sorted(os.listdir(os.path.join(gen_temp_path, '16')))\n",
    "gen_temp_8 = sorted(os.listdir(os.path.join(disc_temp_path, '8')))\n",
    "\n",
    "\n",
    "disc_disp_128 = sorted(os.listdir(os.path.join(disc_disp_path, '128')))\n",
    "disc_disp_64 = sorted(os.listdir(os.path.join(disc_disp_path, '64')))\n",
    "disc_disp_32 = sorted(os.listdir(os.path.join(disc_disp_path, '32')))\n",
    "disc_disp_16 = sorted(os.listdir(os.path.join(disc_disp_path, '16')))\n",
    "\n",
    "gen_disp_64 = sorted(os.listdir(os.path.join(gen_disp_path, '64')))\n",
    "gen_disp_16 = sorted(os.listdir(os.path.join(gen_disp_path, '16')))\n",
    "gen_disp_8 = sorted(os.listdir(os.path.join(disc_disp_path, '8')))\n",
    "\n",
    "tmp_array = [disc_temp_128,disc_temp_64,disc_temp_32,disc_temp_16,gen_temp_8,temp_256]\n",
    "disp_array = [disc_disp_128,disc_disp_64,disc_disp_32,disc_disp_16,gen_disp_8,disp_256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa6c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_array[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e5573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e97ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = [342.4,343.8,342.9,341,340.6,345.4,340.5,340.3,337.8,339.4,337.2,345,343.5,339.2,340.5,337.5,340.4,342.8,338.9,341]\n",
    "disp = [0.4031,0.4140,0.4002,0.3952,0.3912,0.4088,0.3963,0.3956,0.3933,0.3902,0.3886,0.4059,0.4052,0.3996,0.3936,0.3962,0.4052,0.4073,0.3993,0.4006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0421f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(20): \n",
    "    temp[i] = tf.convert_to_tensor(temp[i])\n",
    "    temp[i]=tf.expand_dims(temp[i], axis=0)\n",
    "    temp[i]=tf.broadcast_to(temp[i], (1, 1))\n",
    "    \n",
    "    disp[i] = tf.convert_to_tensor(disp[i])\n",
    "    disp[i]=tf.expand_dims(disp[i], axis=0)\n",
    "    disp[i]=tf.broadcast_to(disp[i], (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec56f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_arr = []\n",
    "\n",
    "#disc\n",
    "X1=get_images(tmp_array[0],disp_array[0],target_elements,20,128)\n",
    "X2=get_images(tmp_array[1],disp_array[1],target_elements,20,64)\n",
    "X3=get_images(tmp_array[2],disp_array[2],target_elements,20,32)\n",
    "X4=get_images(tmp_array[3],disp_array[3],target_elements,20,16)\n",
    "X5 = get_images(tmp_array[4],disp_array[4],target_elements,20,8)\n",
    "\n",
    "inp_256 = get_images(tmp_array[5],disp_array[5],target_elements,20,256)\n",
    "\n",
    "\n",
    "temp = np.array(temp)\n",
    "disp = np.array(disp)\n",
    "\n",
    "#gen - use X2 and X4\n",
    "\n",
    "Y = get_Y(target_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf601a-2294-46cf-9386-127fb7be535d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1=get_images(tmp_array[0],disp_array[0],target_elements,20,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41889a-d066-4993-adaa-98cacdb104a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your image data is stored in the variable 'image'\n",
    "# For example, let's create a sample image with random data\n",
    "import numpy as np\n",
    "image = X5[6]  # Generating a random image with shape (128, 128, 2)\n",
    "print(X1.shape)\n",
    "image1 = image[:, :, 1]\n",
    "plt.imshow(image1,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7d373-11a6-4bdf-ae4c-b7ffedb4226d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your image data is stored in the variable 'image'\n",
    "# For example, let's create a sample image with random data\n",
    "import numpy as np\n",
    "image = X1[1]  # Generating a random image with shape (128, 128, 2)\n",
    "print(X1.shape)\n",
    "image1 = image[:, :, 1]\n",
    "plt.imshow(image1,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08f99f-863e-4641-a01a-dfb1bb7e3002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f6765-2f44-4fd8-9d85-cbb8d1dd4fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_array[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd26b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_data=tf.data.Dataset.from_tensor_slices((inp_256,X1,X5,temp,disp,Y))\n",
    "train_data=train_data.shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a89268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00808e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_temp_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd31a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_temp_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d2986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for elm in disc_temp_128:\n",
    "    i=i+1    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62691fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for elm in disc_temp_64:\n",
    "    i=i+1    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b019aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for elm in target_elements:\n",
    "    j=j+1    \n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931dee1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd7534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff720e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b14841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, n_samples=3):\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _ = generate_real_samples(n_samples, 1)\n",
    "    \n",
    "    # generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "    \n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%06d.png' % (step+1)\n",
    "    plt.savefig(filename1)\n",
    "    plt.close()\n",
    "    # save the generator model\n",
    "    filename2 = 'model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ca759-48ca-4bff-a743-e8627fb01c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def generate_noise(latent_dim):\n",
    "    noise = tf.random.normal([1,latent_dim])\n",
    "    return noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e3e3a-0b42-46de-8809-1a35faf9602c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_noise(100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540af79c-7fe9-4841-baa5-1c9edc9f4b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def define_discriminator(in_shape=(256,256,1)):  \n",
    "\n",
    "    condition = Input(shape=(256,256,2))  \n",
    "    \n",
    "    in_image = Input(shape=in_shape)   #\n",
    "    \n",
    "    #x1 = Input(shape=(128,128,2))\n",
    "  \n",
    "    merge = Concatenate()([condition,in_image])\n",
    "     \n",
    "\n",
    "    disc = Conv2D(64, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    #disc = Concatenate()([disc,x1 ])\n",
    "    disc = BatchNormalization()(disc)\n",
    "    disc = LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = Dropout(0.2)(disc)\n",
    "    \n",
    "    disc = Conv2D(128, (3,3), strides=(2,2), padding='same')(disc)\n",
    "    disc = BatchNormalization()(disc)\n",
    "    disc = LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = Dropout(0.2)(disc)\n",
    "    \n",
    "    disc = Conv2D(256, (3,3), strides=(2,2), padding='same')(disc)\n",
    "    disc = BatchNormalization()(disc)\n",
    "    disc = LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = Dropout(0.2)(disc)\n",
    "    \n",
    "    disc = Conv2D(512, (3,3), strides=(2,2), padding='same')(disc)\n",
    "    disc = BatchNormalization()(disc)\n",
    "    disc = LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = Dropout(0.2)(disc)\n",
    " \n",
    "    layer = Flatten()(disc)\n",
    "   \n",
    "    out_layer = Dense(1)(layer)  \n",
    "\n",
    "    model = Model([in_image, condition], out_layer)\n",
    "    \n",
    "    model.summary()\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e2288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = define_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975ca92-5a0b-43b2-90cf-a377001478ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim=100,nodes=4096):\n",
    "\n",
    "    #g1 = Input(shape=(8,8,2))\n",
    "     \n",
    "    in_label_1 = Input(shape=(1,))  \n",
    "    in_label_2 = Input(shape=(1,))\n",
    "    \n",
    "    latent =  Input(shape=(latent_dim,))\n",
    "    merge = Concatenate()([latent, in_label_1,in_label_2]) \n",
    "    \n",
    "    merge = Dense(nodes)(merge)\n",
    "    gen = Reshape((4, 4, 256))(merge) \n",
    "    \n",
    "    gen = Conv2DTranspose(512, (3,3), strides=(2,2), padding='same')(gen)  \n",
    "    #merge1 = Concatenate()([gen, g1]) \n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    \n",
    "    gen = Conv2DTranspose(256, (3,3), strides=(2,2), padding='same')(gen) \n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same')(gen) \n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    \n",
    "    gen = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same')(gen) \n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    \n",
    "    gen_out = Conv2DTranspose(1, (4,4), strides=(4,4), padding='same',activation='tanh')(gen) \n",
    "    \n",
    "    model = Model([latent, in_label_1,in_label_2], gen_out)\n",
    "    \n",
    "    model.summary()\n",
    "    return model   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5dc888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = define_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505eb7f5-41e5-4385-9a1c-973bb0a750ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def gen_train(tr_size=20,latent_dim=100,nodes=4096):  \n",
    "    \n",
    "    for i in range(tr_size):    \n",
    "        temp1= cv2.imread(gen_temp_64[i])\n",
    "        disp1 = cv2.imread(gen_disp_64[i])\n",
    "        temp2= cv2.imread(gen_temp_16[i])\n",
    "        disp2 = cv2.imread(gen_disp_16[i])\n",
    "\n",
    "        temp_1 = tf.expand_dims(temp1, axis=0)\n",
    "        disp_1 = tf.expand_dims(disp1,axis=0)\n",
    "        temp_2 = tf.expand_dims(temp2, axis=0)\n",
    "        disp_2 = tf.expand_dims(disp2,axis=0)\n",
    "\n",
    "        latent = generate_noise(100)\n",
    "\n",
    "        generator_model = define_generator(latent_dim=latent_dim, nodes=nodes)\n",
    "\n",
    "\n",
    "        gen_output = generator_model([latent, temp_1, disp_1, temp_2, disp_2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb634bf-7c3a-4848-af03-feb3db5cf986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9e06e-4b09-402b-8c24-b5c3933387cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def disc_train(tr_size=20,temp,disp,in_shape=(256,256,1)):\n",
    "    \n",
    "    for i in range(tr_size):\n",
    "        in_image = \n",
    "        \n",
    "        condition = source[i]\n",
    "        \n",
    "        temp1= cv2.imread(disc_temp_128[i])\n",
    "        disp1 = cv2.imread(disc_disp_128[i])\n",
    "        temp2= cv2.imread(disc_temp_64[i])\n",
    "        disp2 = cv2.imread(disc_disp_64[i])\n",
    "        temp3= cv2.imread(disc_temp_32[i])\n",
    "        disp3 = cv2.imread(disc_disp_32[i])\n",
    "        temp4= cv2.imread(disc_temp_16[i])\n",
    "        disp4 = cv2.imread(disc_disp_16[i])\n",
    "        \n",
    "        temp_1 = tf.expand_dims(temp1, axis=0)\n",
    "        disp_1 = tf.expand_dims(disp1,axis=0)\n",
    "        temp_2 = tf.expand_dims(temp2, axis=0)\n",
    "        disp_2 = tf.expand_dims(disp2,axis=0)\n",
    "        temp_3 = tf.expand_dims(temp3, axis=0)\n",
    "        disp_3 = tf.expand_dims(disp3,axis=0)\n",
    "        temp_4 = tf.expand_dims(temp4, axis=0)\n",
    "        disp_4 = tf.expand_dims(disp4,axis=0)\n",
    "    \n",
    "\n",
    "      \n",
    "        \n",
    "        disc_model = define_discriminator(in_shape)\n",
    "        \n",
    "\n",
    "        disc_output = disc_model([in_image,condition, temp_1, disp_1, temp_2, disp_2,temp_3,disp_3,temp_4,disp_4])\n",
    "        \n",
    "      '''  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54fad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def disc_loss(real_output,fake_output):\n",
    "  real_loss=loss(tf.ones_like(real_output),real_output)\n",
    "  fake_loss=loss(tf.zeros_like(fake_output),fake_output)\n",
    "  return real_loss+fake_loss\n",
    "\n",
    "\n",
    "def gen_loss(generated_output):\n",
    "  gan_loss = loss(tf.ones_like(generated_output), generated_output)\n",
    "  gan_loss = tf.cast(gan_loss,tf.float64)\n",
    "  return gan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be49467-4746-4f20-9cf4-b9e037f0352a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_opt=tf.keras.optimizers.Adam(learning_rate=0.0002,beta_1=0.5,beta_2=0.999)\n",
    "disc_opt=tf.keras.optimizers.Adam(learning_rate=0.0002,beta_1=0.5,beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9d032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def generate_noise(latent_dim=100):\n",
    "    noise = tf.random.normal([1,latent_dim])\n",
    "    return noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a35bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def compare_images(latent, t,d,target,epoch):\n",
    "  generated = generator([latent, t,d], training=True)\n",
    "  plt.figure(figsize=(15,5))\n",
    "  \n",
    "  images_list = [target[0], generated[0]]\n",
    "  \n",
    "  title = ['Real (ground truth)', 'Generated Image (fake)']\n",
    "\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.title(title[i])\n",
    "    images_list[i]=images_list[i]/2\n",
    "    images_list[i]+=0.5\n",
    "    plt.imshow(images_list[i],cmap='gray')\n",
    "\n",
    "    plt.axis('off')\n",
    "  plt.suptitle(f'Step {epoch}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113d326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp_256, t,d,real):\n",
    "  with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "    latent =  generate_noise()\n",
    "    g_output = generator([latent, t,d],training=True)\n",
    "    \n",
    "    d_output_real = discriminator([real,inp_256],training=True)\n",
    "    \n",
    "    d_generated_output = discriminator([g_output,inp_256],training=True)\n",
    "    \n",
    "    g_loss_total =gen_loss(d_generated_output)\n",
    "    \n",
    "    d_loss = disc_loss(d_output_real, d_generated_output)\n",
    "    \n",
    "  gradients_generator = g_tape.gradient(g_loss_total, generator.trainable_variables)\n",
    "  gradients_discriminator = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "  gen_opt.apply_gradients(zip(gradients_generator, generator.trainable_variables))\n",
    "  disc_opt.apply_gradients(zip(gradients_discriminator, discriminator.trainable_variables))\n",
    "  return [d_loss,g_loss_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7c459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "def train(train_set, steps):\n",
    "       \n",
    "        losses=[]\n",
    "   \n",
    "        inp_256, X1,X5, T, D, Y =  next(iter(train_set.take(1)))\n",
    "        \n",
    "        for step, (inp, x1, x5,t, d, y) in train_set.repeat().take(steps).enumerate():\n",
    "            print('Step ', step)\n",
    "            if step % 20 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                compare_images(generate_noise(), T, D, Y, step)\n",
    "                print(f\"step: {step}\")\n",
    "            losses.append(train_step(inp, t, d, y))\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd9995-4772-445f-ae0d-30a9a632fcc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from IPython import display\n",
    "\n",
    "def train(train_set, steps ):\n",
    "    for epoch in range(steps//20):\n",
    "        print(f\"Epoch {epoch + 1}/{steps//20}:\")\n",
    "        train_iter = iter(train_set)\n",
    "        \n",
    "        for step in range(steps):\n",
    "            try:\n",
    "                inp_256, X1, X2, X3, X4, T, D, Y = next(train_iter)  \n",
    "                print(T,D)\n",
    "            except StopIteration:\n",
    "                break  \n",
    "            \n",
    "            print('Step ', step)\n",
    "            if step % 20 == 0:\n",
    "                # display.clear_output(wait=True)\n",
    "                compare_images(generate_noise(), T, D, X4, X2, Y, step)\n",
    "                print(f\"step: {step}\")\n",
    "            train_step(inp_256, T, D, X1, X2, X3, X4, Y)\n",
    "            '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11cb6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=train(train_data,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd8f59-141b-4b44-8633-f757aa649370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=np.array(history)\n",
    "history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422a940-8d56-49ad-912f-27f7062a25f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fde8c7-1034-43e1-8d29-53c5d6c3c2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccgan_mod = generator.save(\"ccgan_mod.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7933ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "iter_ = iter(train_data)\n",
    "for i in range(30):\n",
    "    inp_256,X1,X2,X3,X4,T,D,Y = next(iter_)\n",
    "    print(D)\n",
    "    plt.subplot(6,5,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(Y[0],cmap='gray')\n",
    "    \n",
    "\n",
    "    \n",
    "#pred = generator([generate_noise(),T,D,X4,X2],training=False)\n",
    "#plt.imshow(pred[0],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83db2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "train_iter = iter(train_data)\n",
    "for i in range(30):  \n",
    "    inp_256,X1,X2,X3,X4,T,D,Y = next(train_iter)\n",
    "    plt.subplot(6,5,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.imshow(generator([generate_noise(),T,D,X4,X2],training=False)[0],cmap='gray')\n",
    "    plt.imshow(Y[0],cmap='gray')\n",
    "    \n",
    "   \n",
    "    \n",
    "#pred = generator([generate_noise(),T,D,X4,X2],training=False)\n",
    "#plt.imshow(pred[0],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7a7e0-7ff2-4f88-a4e9-30355ae818aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604e579-7ede-4860-a8fb-cb62aa03497c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_iter = iter(train_data)\n",
    "inp_256,X1,X2,X3,X4,T,D,Y = next(train_iter)\n",
    "print(np.array(inp_256).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375472d8-8079-4d7e-a6fc-824d6196ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_256, x1,x5, t, d, y =  next(iter(train_data.take(1)))\n",
    "print(t,d)\n",
    "img = generator.predict([generate_noise(), t,d,x5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[0],cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y[0],cmap='gray')\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73909c64-b4c4-4e89-bf26-f1fd6b09b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your image data is stored in the variable 'image'\n",
    "# For example, let's create a sample image with random data\n",
    "import numpy as np\n",
    "image = x1[0]  # Generating a random image with shape (128, 128, 2)\n",
    "print(x1.shape)\n",
    "image1 = image[:, :, 1:2]\n",
    "plt.imshow(image1,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd537028-bfad-4399-8ab0-85127724db05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31c6a6-5ea9-4b4a-9bd6-d10beea43b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_=np.array(loss)\n",
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842fabfc-9fd6-400a-b308-eecbdb47ce0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_256, x1, x2,x3, x4, t, d, y =  next(iter(train_data.take(1)))\n",
    "print(t,d)\n",
    "img = generator.predict([generate_noise(), t,d,x4,x2])\n",
    "plt.imshow(img[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0413d-e11d-4ad6-890c-5f76e0f9dd49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
