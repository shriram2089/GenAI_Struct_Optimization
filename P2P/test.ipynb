{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86331ee4-5950-4913-a4b9-58d7a39acefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.cuda.set_device(device)\n",
    "print(device)\n",
    "\n",
    "print(\"modules imported\")\n",
    "\n",
    "x_train_tmp_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\DATASET\\short_range\\temp_short\"\n",
    "x_train_dsp_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\DATASET\\short_range\\disp_short\"\n",
    "y_train_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\DATASET\\CIRCULAR_VANE_Shape_Images_1559\"\n",
    "\n",
    "def sort_img(path):\n",
    "    dict1 = {}\n",
    "    lst = [0]*1560\n",
    "    for i in path:\n",
    "        dict1[int(i[i.index('(')+1:i.index(')')])] = i\n",
    "    for j in range(1,1560):\n",
    "        lst[j] = dict1[j]\n",
    "    return lst[1:]\n",
    "\n",
    "'''\n",
    "x_tmp_elements = sort_img(os.listdir(x_train_tmp_folder_path))\n",
    "x_dsp_elements = sort_img(os.listdir(x_train_dsp_folder_path))\n",
    "y_elements = sort_img(os.listdir(y_train_folder_path))\n",
    "\n",
    "'''\n",
    "x_tmp_elements = os.listdir(x_train_tmp_folder_path)\n",
    "x_dsp_elements = os.listdir(x_train_dsp_folder_path)\n",
    "y_elements = os.listdir(y_train_folder_path)\n",
    "\n",
    "\n",
    "batch_size_list = [4, 16, 32, 64, 128, 128, 128, 64, 32, 16, 32, 64, 128]\n",
    "data_list = [20, 100, 200, 300, 500, 800, 1200, 1200, 1200, 1200, 1200, 1200, 1200]\n",
    "epoch_list = [50]*4 + [200]*6 + [400, 300, 200]\n",
    "\n",
    "def get_images(tmp_elements, disp_elements, y_elements, size):\n",
    "    X = np.zeros((size, 2, 256, 256))\n",
    "    Y = np.zeros((size, 1, 256, 256))\n",
    "    for index, (tmp_element, dsp_element) in enumerate(zip(tmp_elements, disp_elements)):\n",
    "        tmp_element_path = os.path.join(x_train_tmp_folder_path, tmp_element)\n",
    "        dsp_element_path = os.path.join(x_train_dsp_folder_path, dsp_element)\n",
    "        img_tmp = imread(tmp_element_path)\n",
    "        img_dsp = imread(dsp_element_path)\n",
    "\n",
    "        img_tmp = img_tmp.reshape((1, 256, 256))\n",
    "        img_dsp = img_dsp.reshape((1, 256, 256))\n",
    "\n",
    "        img_combined = (np.concatenate((img_tmp, img_dsp), axis=0)-0.5)/0.5\n",
    "        X[index] = img_combined\n",
    "\n",
    "    for index, Y_train_element in enumerate(y_elements):\n",
    "        element_path = os.path.join(y_train_folder_path, Y_train_element)\n",
    "        img = imread(element_path)\n",
    "        img = np.mean(img, axis=2)\n",
    "        img = img/127.5-1\n",
    "        img = img.reshape((1, 256, 256))\n",
    "        Y[index] = img\n",
    "    return X, Y\n",
    "\n",
    "x, y = get_images(x_tmp_elements, x_dsp_elements, y_elements, len(x_tmp_elements))\n",
    "\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, batch_norm=True):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels) if batch_norm else None\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        nn.init.normal_(self.conv.weight, mean=0.0, std=0.02)\n",
    "        if self.conv.bias is not None:\n",
    "            nn.init.constant_(self.conv.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x.float())\n",
    "        if self.batch_norm is not None:\n",
    "            x = self.batch_norm(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(0.5) if dropout else None\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        nn.init.normal_(self.conv_transpose.weight, mean=0.0, std=0.02)\n",
    "        if self.conv_transpose.bias is not None:\n",
    "            nn.init.constant_(self.conv_transpose.bias, 0.0)\n",
    "\n",
    "    def forward(self, x, skip_con):\n",
    "        x = self.conv_transpose(x.float())\n",
    "        x = self.batch_norm(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = torch.cat((x, skip_con.float()), dim=1)\n",
    "        x = self.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8521bbe-c5af-4025-8ba7-935b7a12046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 128, 128, 128]           4,224\n",
      "         LeakyReLU-2        [-1, 128, 128, 128]               0\n",
      "      EncoderBlock-3        [-1, 128, 128, 128]               0\n",
      "            Conv2d-4          [-1, 256, 64, 64]         524,544\n",
      "         LeakyReLU-5          [-1, 256, 64, 64]               0\n",
      "       BatchNorm2d-6          [-1, 256, 64, 64]             512\n",
      "      EncoderBlock-7          [-1, 256, 64, 64]               0\n",
      "            Conv2d-8          [-1, 512, 32, 32]       2,097,664\n",
      "         LeakyReLU-9          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-10          [-1, 512, 32, 32]           1,024\n",
      "     EncoderBlock-11          [-1, 512, 32, 32]               0\n",
      "           Conv2d-12         [-1, 1024, 16, 16]       8,389,632\n",
      "        LeakyReLU-13         [-1, 1024, 16, 16]               0\n",
      "      BatchNorm2d-14         [-1, 1024, 16, 16]           2,048\n",
      "     EncoderBlock-15         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-16           [-1, 1024, 8, 8]      16,778,240\n",
      "        LeakyReLU-17           [-1, 1024, 8, 8]               0\n",
      "      BatchNorm2d-18           [-1, 1024, 8, 8]           2,048\n",
      "     EncoderBlock-19           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-20           [-1, 1024, 4, 4]      16,778,240\n",
      "        LeakyReLU-21           [-1, 1024, 4, 4]               0\n",
      "      BatchNorm2d-22           [-1, 1024, 4, 4]           2,048\n",
      "     EncoderBlock-23           [-1, 1024, 4, 4]               0\n",
      "           Conv2d-24           [-1, 1024, 2, 2]      16,778,240\n",
      "        LeakyReLU-25           [-1, 1024, 2, 2]               0\n",
      "      BatchNorm2d-26           [-1, 1024, 2, 2]           2,048\n",
      "     EncoderBlock-27           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-28           [-1, 2048, 1, 1]      33,556,480\n",
      "             ReLU-29           [-1, 2048, 1, 1]               0\n",
      "  ConvTranspose2d-30           [-1, 2048, 2, 2]      67,110,912\n",
      "             ReLU-31           [-1, 2048, 2, 2]               0\n",
      "      BatchNorm2d-32           [-1, 2048, 2, 2]           4,096\n",
      "          Dropout-33           [-1, 2048, 2, 2]               0\n",
      "     DecoderBlock-34           [-1, 3072, 2, 2]               0\n",
      "  ConvTranspose2d-35           [-1, 1024, 4, 4]      50,332,672\n",
      "             ReLU-36           [-1, 1024, 4, 4]               0\n",
      "      BatchNorm2d-37           [-1, 1024, 4, 4]           2,048\n",
      "          Dropout-38           [-1, 1024, 4, 4]               0\n",
      "     DecoderBlock-39           [-1, 2048, 4, 4]               0\n",
      "  ConvTranspose2d-40           [-1, 1024, 8, 8]      33,555,456\n",
      "             ReLU-41           [-1, 1024, 8, 8]               0\n",
      "      BatchNorm2d-42           [-1, 1024, 8, 8]           2,048\n",
      "          Dropout-43           [-1, 1024, 8, 8]               0\n",
      "     DecoderBlock-44           [-1, 2048, 8, 8]               0\n",
      "  ConvTranspose2d-45         [-1, 1024, 16, 16]      33,555,456\n",
      "             ReLU-46         [-1, 1024, 16, 16]               0\n",
      "      BatchNorm2d-47         [-1, 1024, 16, 16]           2,048\n",
      "     DecoderBlock-48         [-1, 2048, 16, 16]               0\n",
      "  ConvTranspose2d-49          [-1, 512, 32, 32]      16,777,728\n",
      "             ReLU-50          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-51          [-1, 512, 32, 32]           1,024\n",
      "     DecoderBlock-52         [-1, 1024, 32, 32]               0\n",
      "  ConvTranspose2d-53          [-1, 256, 64, 64]       4,194,560\n",
      "             ReLU-54          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-55          [-1, 256, 64, 64]             512\n",
      "     DecoderBlock-56          [-1, 512, 64, 64]               0\n",
      "  ConvTranspose2d-57        [-1, 128, 128, 128]       1,048,704\n",
      "             ReLU-58        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-59        [-1, 128, 128, 128]             256\n",
      "     DecoderBlock-60        [-1, 256, 128, 128]               0\n",
      "  ConvTranspose2d-61          [-1, 1, 256, 256]           4,097\n",
      "             Tanh-62          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 301,508,609\n",
      "Trainable params: 301,508,609\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 261.75\n",
      "Params size (MB): 1150.16\n",
      "Estimated Total Size (MB): 1412.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_shape=(2, 256, 256)):\n",
    "        super(UNet, self).__init__()\n",
    "        self.e1 = EncoderBlock(input_shape[0], 128, batch_norm=False)\n",
    "        self.e2 = EncoderBlock(128, 256)\n",
    "        self.e3 = EncoderBlock(256, 512)\n",
    "        self.e4 = EncoderBlock(512, 1024)\n",
    "        self.e5 = EncoderBlock(1024, 1024)\n",
    "        self.e6 = EncoderBlock(1024, 1024)\n",
    "        self.e7 = EncoderBlock(1024, 1024)\n",
    "\n",
    "        self.b = nn.Conv2d(1024, 2048, kernel_size=4, stride=2, padding=1)\n",
    "        nn.init.normal_(self.b.weight, mean=0.0, std=0.02)\n",
    "        if self.b.bias is not None:\n",
    "            nn.init.constant_(self.b.bias, 0.0)\n",
    "        self.b_relu = nn.ReLU()\n",
    "\n",
    "        self.d1 = DecoderBlock(2048, 2048)\n",
    "        self.d2 = DecoderBlock(3072, 1024)\n",
    "        self.d3 = DecoderBlock(2048, 1024)\n",
    "        self.d4 = DecoderBlock(2048, 1024, dropout=False)\n",
    "        self.d5 = DecoderBlock(2048, 512, dropout=False)\n",
    "        self.d6 = DecoderBlock(1024, 256, dropout=False)\n",
    "        self.d7 = DecoderBlock(512, 128, dropout=False)\n",
    "\n",
    "        self.output_layer = nn.ConvTranspose2d(256, 1, kernel_size=4, stride=2, padding=1)\n",
    "        nn.init.normal_(self.output_layer.weight, mean=0.0, std=0.02)\n",
    "        if self.output_layer.bias is not None:\n",
    "            nn.init.constant_(self.output_layer.bias, 0.0)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(e1)\n",
    "        e3 = self.e3(e2)\n",
    "        e4 = self.e4(e3)\n",
    "        e5 = self.e5(e4)\n",
    "        e6 = self.e6(e5)\n",
    "        e7 = self.e7(e6)\n",
    "\n",
    "        b = self.b(e7)\n",
    "        b = self.b_relu(b)\n",
    "\n",
    "        d1 = self.d1(b, e7)\n",
    "        d2 = self.d2(d1, e6)\n",
    "        d3 = self.d3(d2, e5)\n",
    "        d4 = self.d4(d3, e4)\n",
    "        d5 = self.d5(d4, e3)\n",
    "        d6 = self.d6(d5, e2)\n",
    "        d7 = self.d7(d6, e1)\n",
    "\n",
    "        output = self.output_layer(d7)\n",
    "        output = self.tanh(output)\n",
    "        return output\n",
    "model = UNet()\n",
    "model.to(device)\n",
    "\n",
    "summary(model, input_size=(2, 256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063f6aa-d797-493a-927c-ce11170f48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}', leave=False):\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).float()  # Ensure inputs are float32\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "'''\n",
    "for i in range(13):\n",
    "    x_np, y_np = x[:data_list[i]], y[:data_list[i]]\n",
    "    print(data_list[i], \",\", batch_size_list[i])\n",
    "    x_tensor = torch.tensor(x_np).to(device)\n",
    "    y_tensor = torch.tensor(y_np).to(device)\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size_list[i])\n",
    "    train(model, dataloader, criterion, optimizer, epoch_list[i], device)\n",
    "    torch.save(model, f'short_p2p_unet_gpu0_{i}.pth')\n",
    "\n",
    "print(\"Model saved\")\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_main",
   "language": "python",
   "name": "gpu_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
