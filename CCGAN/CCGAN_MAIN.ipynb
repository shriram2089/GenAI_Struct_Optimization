{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb11df8-4601-456b-b294-76d96717e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, ReLU, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee17c798-a866-48bc-8888-14fee7a765b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tmp_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\DATASET\\OLD_20\\disp_20\"\n",
    "x_train_dsp_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\DATASET\\OLD_20\\temp_20\"\n",
    "y_train_folder_path = r\"C:\\Users\\shrir\\OneDrive\\Desktop\\GAN\\GAN_PS\\DATASET\\OLD_20\\outputs\"\n",
    "\n",
    "x_tmp_elements = os.listdir(x_train_tmp_folder_path)\n",
    "x_dsp_elements = os.listdir(x_train_dsp_folder_path)\n",
    "y_elements = os.listdir(y_train_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96178575-8052-4d0f-9a01-48ebcf110627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVELOPING X_train MATRIX\n",
    "\n",
    "def get_images(tmp_elements,disp_elements,y_elements,size):\n",
    "  X= np.zeros((size,256,256,2))\n",
    "  Y= np.zeros((size,256,256,1))\n",
    "  for index, (tmp_element, dsp_element) in enumerate(zip(tmp_elements, disp_elements)):\n",
    "      # Load images for each channel\n",
    "      tmp_element_path = os.path.join(x_train_tmp_folder_path, tmp_element)\n",
    "      dsp_element_path = os.path.join(x_train_dsp_folder_path, dsp_element)\n",
    "      img_tmp = imread(tmp_element_path)\n",
    "      img_dsp = imread(dsp_element_path)\n",
    "\n",
    "      # Reshape images for each channel\n",
    "      img_tmp = img_tmp.reshape((256,256, 1))\n",
    "      img_dsp = img_dsp.reshape((256,256, 1))\n",
    "\n",
    "      # Combine channels\n",
    "      img_combined = (np.concatenate((img_tmp, img_dsp), axis=2)-0.5)/0.5\n",
    "\n",
    "      # Assign to X_train\n",
    "      X[index] = img_combined\n",
    "\n",
    "  # DEVELOPING Y_train MATRIX\n",
    "  for index,Y_train_element in enumerate(y_elements):\n",
    "      element_path = os.path.join(y_train_folder_path, Y_train_element)\n",
    "      img = imread(element_path)\n",
    "      img = np.mean(img, axis=2)\n",
    "      img = img/255\n",
    "      img = img.reshape((256, 256, 1))\n",
    "      Y[index] = img\n",
    "  return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4153ce02-3512-4cd8-8bfd-2226ec34fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_images(x_tmp_elements,x_dsp_elements,y_elements,len(x_tmp_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a01ab4-45cc-4b30-8b9f-b54ef63678f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=tf.data.Dataset.from_tensor_slices((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fa53da-b095-4033-aef0-f8dffbcd2c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(256, 256, 2), dtype=tf.float64, name=None), TensorSpec(shape=(256, 256, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7206426c-7870-4f2e-a320-eef954d6eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[342.4      0.4031]\n",
      " [343.8      0.414 ]\n",
      " [342.9      0.4002]\n",
      " [341.       0.3952]\n",
      " [340.6      0.3912]\n",
      " [345.4      0.4088]\n",
      " [340.5      0.3963]\n",
      " [340.3      0.3956]\n",
      " [337.8      0.3933]\n",
      " [339.4      0.3902]\n",
      " [337.2      0.3886]\n",
      " [345.       0.4059]\n",
      " [343.5      0.4052]\n",
      " [339.2      0.3996]\n",
      " [340.5      0.3936]\n",
      " [337.5      0.3962]\n",
      " [340.4      0.4052]\n",
      " [342.8      0.4073]\n",
      " [338.9      0.3993]\n",
      " [341.       0.4006]], shape=(20, 2), dtype=float32)\n",
      "(20, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp = [342.4, 343.8, 342.9, 341, 340.6, 345.4, 340.5, 340.3, 337.8, 339.4, 337.2, 345, 343.5, 339.2, 340.5, 337.5, 340.4, 342.8, 338.9, 341]\n",
    "disp = [0.4031, 0.4140, 0.4002, 0.3952, 0.3912, 0.4088, 0.3963, 0.3956, 0.3933, 0.3902, 0.3886, 0.4059, 0.4052, 0.3996, 0.3936, 0.3962, 0.4052, 0.4073, 0.3993, 0.4006]\n",
    "\n",
    "# Convert lists to TensorFlow tensors\n",
    "temp_tensor = tf.constant(temp)\n",
    "disp_tensor = tf.constant(disp)\n",
    "\n",
    "# Concatenate tensors along a new dimension (1D array for each)\n",
    "conditions = tf.concat([temp_tensor[:, tf.newaxis], disp_tensor[:, tf.newaxis]], axis=1)\n",
    "\n",
    "# Print the concatenated tensor and its shape\n",
    "print(conditions)\n",
    "print(conditions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45072ac8-2828-4acf-bd73-64f9525f3647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d34be8c-4c8a-404f-8339-19f202cec53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "C5, C6, C7, C8 = 1.0, 1.0, 1.0, 1.0\n",
    "sigma = 0.2\n",
    "kappa = 0.1\n",
    "\n",
    "# Helper function to compute vicinal points and weights\n",
    "def compute_vicinal_points_and_weights(y, eps):\n",
    "    y_eps = y + eps\n",
    "    weights = tf.exp(-tf.square(eps) / (2 * tf.square(sigma)))\n",
    "    return y_eps, weights\n",
    "\n",
    "# Indicator function\n",
    "def indicator_function(y, y_tilde, kappa):\n",
    "    return tf.cast(tf.abs(y - y_tilde) <= kappa, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a29a365-314b-4067-a075-ccdc492dd6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 102)          0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32768)        3375104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 16, 16, 128)  0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 128)  512        ['reshape[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 16, 16, 128)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 128)  262272     ['leaky_re_lu[0][0]']            \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 128)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 64)  131136      ['leaky_re_lu_1[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 32  32800      ['leaky_re_lu_2[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 32  128        ['conv2d_transpose_2[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 128, 128, 32  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 1)  513        ['leaky_re_lu_3[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 1)  0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,803,233\n",
      "Trainable params: 3,802,529\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, BatchNormalization, LeakyReLU, Conv2DTranspose, Concatenate, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_generator(latent_dim, condition_dim):\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    condition = Input(shape=(condition_dim,))\n",
    "\n",
    "    # Combine noise and condition inputs\n",
    "    x = Concatenate()([noise, condition])\n",
    "\n",
    "    # Project and reshape\n",
    "    x = Dense(128 * 16 * 16)(x)  # Start with a projection size that can be reshaped into 16x16x128\n",
    "    x = Reshape((16, 16, 128))(x)  # Reshape according to the projected size\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # Upsampling layers\n",
    "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)  # Upsample to 32x32\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same')(x)  # Upsample to 64x64\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same')(x)  # Upsample to 128x128\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Conv2DTranspose(1, (4, 4), strides=(2, 2), padding='same')(x)  # Upsample to 256x256\n",
    "    img = Activation('tanh')(x)  # Use 'tanh' activation for final image output\n",
    "\n",
    "    return Model([noise, condition], img)\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 100\n",
    "condition_dim = 2\n",
    "generator = build_generator(latent_dim, condition_dim)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a73b5885-13f0-4741-b25d-672b4f3a915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape, condition_dim):\n",
    "    img = Input(shape=image_shape)\n",
    "    condition = Input(shape=(condition_dim,))\n",
    "\n",
    "    x = Conv2D(64, (4, 4), strides=(2, 2), padding='same')(img)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x, condition])\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model([img, condition], x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adade815-4e00-4a3b-8553-5f8440cb4871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 64  1088        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 128, 128, 64  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 128, 64  0           ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 128)  131200      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 64, 64, 128)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64, 64, 128)  0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 524288)       0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 524290)       0           ['flatten[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            524291      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 656,579\n",
      "Trainable params: 656,579\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = build_discriminator((256,256,1),2)\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0628902-9688-4779-9551-cdf78abde55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvdl_loss(y_real, y_fake, D_real, D_fake, kappa, C5,C6):\n",
    "    C5 = tf.cast(C5, tf.float32)\n",
    "    C6 = tf.cast(C6, tf.float32)\n",
    "    N_r = tf.shape(y_real)[0]\n",
    "    N_g = tf.shape(y_fake)[0]\n",
    "    N_r = tf.cast(N_r, tf.float32)\n",
    "    N_g = tf.cast(N_g, tf.float32)\n",
    "\n",
    "    # Ensure epsilon is a tensor with the correct type\n",
    "    y_real_eps = tf.cast(tf.constant(1e-8), tf.float32)\n",
    "    y_fake_eps = tf.cast(tf.constant(1e-8), tf.float32)\n",
    "\n",
    "    def indicator_function(y, y_eps, kappa):\n",
    "        return tf.cast(tf.reduce_mean(tf.abs(y - y_eps), axis=1) < kappa, tf.float32)\n",
    "\n",
    "    term1 = tf.reduce_mean(indicator_function(y_real, y_real_eps, kappa) * tf.math.log(D_real + y_real_eps))\n",
    "    term2 = tf.reduce_mean(indicator_function(y_fake, y_fake_eps, kappa) * tf.math.log(1 - D_fake + y_fake_eps))\n",
    "\n",
    "    loss = -C5 / N_r * term1 - C6 / N_g * term2\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def svdl_loss(y_real, y_fake, D_real, D_fake, sigma, C7, C8):\n",
    "    N_r = tf.shape(y_real)[0]\n",
    "    N_g = tf.shape(y_fake)[0]\n",
    "    N_r = tf.cast(N_r, tf.float32)\n",
    "    N_g = tf.cast(N_g, tf.float32)\n",
    "    \n",
    "    C7 = tf.cast(C7, tf.float32)\n",
    "    C8 = tf.cast(C8, tf.float32)\n",
    "    \n",
    "    eps_r = tf.random.normal(tf.shape(y_real), mean=0.0, stddev=sigma)\n",
    "    eps_g = tf.random.normal(tf.shape(y_fake), mean=0.0, stddev=sigma)\n",
    "\n",
    "    def compute_vicinal_points_and_weights(y, eps):\n",
    "        y_eps = y + eps\n",
    "        w = 1.0 / (tf.sqrt(2.0 * tf.constant(np.pi)) * sigma) * tf.exp(-tf.square(eps) / (2.0 * tf.square(sigma)))\n",
    "        return y_eps, w\n",
    "\n",
    "    y_real_eps, w_real = compute_vicinal_points_and_weights(y_real, eps_r)\n",
    "    y_fake_eps, w_fake = compute_vicinal_points_and_weights(y_fake, eps_g)\n",
    "\n",
    "    term1 = tf.reduce_mean(w_real * tf.math.log(D_real + 1e-8))\n",
    "    term2 = tf.reduce_mean(w_fake * tf.math.log(1 - D_fake + 1e-8))\n",
    "\n",
    "    loss = -C7 / N_r * term1 - C8 / N_g * term2\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2b99d5-60b4-4fef-aa0b-3a3d93834a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(D, G, z, y, sigma):\n",
    "    # Generate noise from a normal distribution\n",
    "    epsilon = tf.random.normal(shape=tf.shape(y), mean=0.0, stddev=sigma)\n",
    "    \n",
    "    # Generate images from the generator\n",
    "    generated_images = G([z, y], training=True)\n",
    "    \n",
    "    # Get the discriminator's output for the generated images\n",
    "    D_output = D([generated_images, y + epsilon], training=True)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = -tf.reduce_mean(tf.math.log(D_output + 1e-10))  # Adding a small constant to avoid log(0)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf4a463-7add-44c9-af6a-49aab71ae67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(noise, condition,target,epoch):\n",
    "  generated = generator.predict([noise, condition])\n",
    "  plt.figure(figsize=(15,5))\n",
    "\n",
    "  images_list = [target[0], generated[0]]\n",
    "  title = ['Real (ground truth)', 'Generated Image (fake)']\n",
    "\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(images_list[i] * 0.5 + 0.5,cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.suptitle(f'EPOCH {epoch}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc9bdc7-9f49-4d5a-9a78-66eb016eb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, latent_dim, condition_dim, epochs, batch_size):\n",
    "    # Optimizers\n",
    "    d_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    g_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "    NOISE = np.random.normal(0, 1, (1, latent_dim))\n",
    "    \n",
    "    CONDITION = X_train[0]\n",
    "    CONDITION = tf.expand_dims(CONDITION,axis=0)\n",
    "    \n",
    "    REAL = y_train[0]\n",
    "    REAL = tf.expand_dims(REAL,axis=0)\n",
    "    print(CONDITION.shape)\n",
    "    print(REAL.shape)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Generate noise and conditions\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        #conditions = np.random.uniform(-1, 1, (batch_size, condition_dim))\n",
    "\n",
    "        # Generate fake images\n",
    "        \n",
    "\n",
    "        # Select a random batch of real images\n",
    "        #idx = np.random.randint(0, y_train.shape[0], batch_size)\n",
    "        \n",
    "        ids = tf.random.shuffle(tf.range(X_train.shape[0]))[:batch_size]\n",
    "        real_conditions = tf.gather(X_train, ids)\n",
    "        gen_imgs = generator.predict([noise, real_conditions])\n",
    "        \n",
    "        real_imgs = tf.gather(y_train,ids)\n",
    "        \n",
    "\n",
    "        # Discriminator loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            D_real = discriminator([real_imgs, real_conditions])\n",
    "            D_fake = discriminator([gen_imgs, real_conditions])\n",
    "            \n",
    "            d_loss = hvdl_loss(real_conditions, conditions, D_real, D_fake, kappa,C5,C6) + svdl_loss(real_conditions, conditions, D_real, D_fake,sigma, C7, C8 )\n",
    "            \n",
    "        grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "        # Generator loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            gen_imgs = generator([noise, conditions])\n",
    "            D_fake = discriminator([gen_imgs, conditions])\n",
    "            g_loss = generator_loss(discriminator,generator, noise, rea, sigma)\n",
    "            \n",
    "        grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "\n",
    "        if(epoch%5==0):\n",
    "            compare_images(NOISE,CONDITION, REAL, 0)\n",
    "\n",
    "        print(f'{epoch}/{epochs}, d_loss: {d_loss.numpy()}, g_loss: {g_loss.numpy()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980f0ec2-5020-4efd-8359-a614bfe38de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 256, 256, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f5db3a-7fb1-488d-a49b-37227b4f1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "latent_dim = 100\n",
    "condition_dim = 2  # Two conditions: temp and disp\n",
    "image_shape = (256, 256, 1)  # Assuming grayscale images\n",
    "\n",
    "# Build and compile models\n",
    "generator = build_generator(latent_dim, condition_dim)\n",
    "discriminator = build_discriminator(image_shape, condition_dim)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18d5ee-3071-4626-8ff4-5edf8e782987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = conditions\n",
    "y_train = y\n",
    "# Training\n",
    "train(generator, discriminator, latent_dim, condition_dim, epochs=500, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddf28a9b-9cd2-40f7-a9e0-72d98b6f802a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([340.5   ,   0.3963], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dda1e18-620d-4819-adf8-b0adc7f9e8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65460cf4-3880-4246-a39c-1ea1135a8318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 3 0 4]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([9, 3, 0, 4])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m real_imgs \u001b[38;5;241m=\u001b[39m y_train[idx]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(idx)\n\u001b[1;32m----> 4\u001b[0m real_conditions \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_main\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_main\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:899\u001b[0m, in \u001b[0;36m_check_index\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m    894\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    897\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[0;32m    898\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[1;32m--> 899\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[1;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([9, 3, 0, 4])"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, y_train.shape[0], 4)\n",
    "real_imgs = y_train[idx]\n",
    "print(idx)\n",
    "real_conditions = X_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2caef70-cb21-488b-bda1-713a47cf6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[340.6      0.3912]\n",
      " [338.9      0.3993]\n",
      " [343.8      0.414 ]\n",
      " [342.9      0.4002]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "selected_indices = tf.random.shuffle(tf.range(X_train.shape[0]))[:4]\n",
    "selected_samples = tf.gather(X_train, selected_indices)\n",
    "\n",
    "# Print selected samples\n",
    "print(selected_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362531a8-b565-4d00-9f50-2828995764ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_main",
   "language": "python",
   "name": "gpu_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
